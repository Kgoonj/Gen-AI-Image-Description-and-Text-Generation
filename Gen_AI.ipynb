{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpXF1IEqrBEu",
        "outputId": "00a395f6-1c80-45ed-cff9-de5950e857e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/155.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m112.6/155.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcvZlKYWrPAK",
        "outputId": "8833b4e2-d788-4b9b-fc8f-89a1ace2fc39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgzwLUfInTcL"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "import google.generativeai as genai\n",
        "from IPython.display import display, Markdown\n",
        "import PIL.Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import textwrap\n",
        "import google.generativeai as genai\n",
        "from IPython.display import display, Markdown\n",
        "from PIL import Image\n",
        "\n",
        "# Function to format response as Markdown\n",
        "def to_markdown(text):\n",
        "    return Markdown(textwrap.indent(text, \"> \", predicate=lambda _: True))\n",
        "\n",
        "# Your actual API key goes here (this is sensitive, don't hard-code it publicly)\n",
        "GOOGLE_API_KEY = \"AIzaSyD2Bl6VHV92nX-h3vPNSoNt5jvItt1I2UI\"\n",
        "\n",
        "# Configure API\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Initialize model\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")  # \"gemini-2.0-flash\" doesn't exist yet, prob meant this\n",
        "\n",
        "# Generate content\n",
        "response = model.generate_content(\"What is Gemini AI?\")\n",
        "\n",
        "# Display the result in Markdown\n",
        "display(to_markdown(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "n8t7BRttni2y",
        "outputId": "33ce55cf-d79e-4ae8-f79f-098fff7bcc08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Gemini is Google's large multimodal AI model.  Unlike models that specialize in just text or images, Gemini is designed to work with multiple modalities, meaning it can understand and generate text, code, images, audio, and video.  Google positions it as a competitor to OpenAI's GPT-4 and other leading large language models.\n> \n> Key features and capabilities often highlighted include:\n> \n> * **Multimodal Capabilities:**  Its ability to handle various input and output formats sets it apart.  You can give it text prompts and get image responses, or ask questions about a video, and receive a text summary.\n> \n> * **Reasoning and Problem-Solving:**  Gemini is touted for its advanced reasoning and problem-solving abilities, exceeding previous models in benchmark tests.\n> \n> * **Context Understanding:**  It aims to understand the context of a conversation or task more comprehensively.\n> \n> * **Integration with Google Services:**  Google plans to integrate Gemini into many of its products and services, making it accessible to a vast user base.\n> \n> However,  specific details about its architecture and training data are not publicly available to the same extent as some other models.  Like other large language models, it's likely trained on massive datasets of text and code, along with other multimodal data.\n> \n> In short, Gemini is a powerful, versatile AI model that aims to be a leading contender in the field, offering a broader range of capabilities than many other existing models.  But its full potential and limitations are still being explored and revealed over time.\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "    if 'generateContent' in m.supported_generation_methods:\n",
        "        print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "wq9LyDjWuKMb",
        "outputId": "48bb2bcc-343f-412c-f562-61c31e5d2994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.5-pro-exp-03-25\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-04-17\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/learnlm-1.5-pro-experimental\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "img = Image.open(r\"/content/images.jpeg\")  # e.g., \"math_problem.jpg\""
      ],
      "metadata": {
        "id": "KOWUqFg_uPTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"describe the image\", img], stream=True)\n",
        "response.resolve()\n",
        "\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "wO2qrMT4uS3F",
        "outputId": "9126918c-8afb-4631-ab51-cf3ee58adfc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> That's a photo of a young boy, appearing to be around elementary school age, with his forehead pressed against a chalkboard covered in complex mathematical equations. \n> \n> \n> He seems frustrated or overwhelmed by the math problems. His posture conveys weariness or defeat.  The focus is on the boy's expression and his proximity to the seemingly daunting equations, creating a visual metaphor for struggling with schoolwork or a difficult concept. The image is sharply focused on the boy, with the chalkboard slightly blurred in the background, drawing the viewer's attention to the boy's emotional state.\n"
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}